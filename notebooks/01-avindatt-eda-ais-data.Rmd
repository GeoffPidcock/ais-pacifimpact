---
title: "EDA - Pacific AIS Data"
author: "Avin Datt - PacifImpact"
date: "06 September 2020"
output: 
  github_document:
     df_print: "kable"
editor_options: 
  chunk_output_type: console
---


# Scope 

1. Explore data features. Understand summary and values. 
2. Apply algorithms to reduce noise as outlined by [UNSTATS](https://unstats.un.org/wiki/display/AIS/AIS+data+at+the+UN+Global+Platform).
3. Create new data features using draught, time and other dimensions. 
4. Create common model to share that can be used in conjunction with trade, and economic research by PacifImpact. 


# Load Libraries

```{r load libs}
# Load data.table library
if (!require(data.table)) {
  install.packages("data.table")
  library(data.table)
}

# Load DBI library
if (!require(DBI)) {
  install.packages("DBI")
  library(DBI)
}

# Load DBI library
if (!require(RPostgres)) {
  install.packages("RPostgres")
  library(RPostgres)
}

# Load SmartEDA library
if (!require(SmartEDA)) {
  install.packages("SmartEDA")
  library(SmartEDA)
}
```

# Read AIS Cook Islands.

Read the files extracted from UNGP for Cook Islands. 

```{r}
# Cook Islands. files
file.list <- list.files(
  path = "./data/external/ais_ck/", 
  pattern='*.csv'
  )


# Read files in bulk
cklist.list <- lapply(
  paste0("./data/external/ais_ck/",
         file.list),
  fread
  )


# turn into one table 
cklist.list <- rbindlist(
  cklist.list
  )


head(cklist.list)
```

## Exploration 

1. Convert dtg and eta to as.POSIXct(x, tz = "", ...)

```{r}
# Change from char to posixct 
cklist.list[,
            `:=` (dtg = gsub("T",
                             " ",
                             dtg
                             )
                  )][,
                     `:=` (dtg = gsub(".000Z",
                             "",
                             dtg
                             )
                           )]


cklist.list[,
            `:=` (dtg = strptime(dtg, "%Y-%m-%d %H:%M:%S")
                  )]


# check summary 
cklist.list[,
            summary(dtg)]
```


```{r}
# Check out dataset quality
ExpData(
  data = cklist.list,
  type = 1
  )
```


```{r}
# Check out data feature quality
ExpData(
  data = cklist.list,
  type = 2
  )
```


```{r}
# Statistics for Numerical features 
data.table(
  ExpNumStat(
    cklist.list,
    by = "A",
    gp = NULL,
    Qnt = NULL,
    Nlim = 10,
    MesofShape = 2,
    Outlier = TRUE,
    round = 3,
    dcast = FALSE,
    val = NULL
  )
)
```

## Definitions Numerical Features

[Definitions available in pdf](https://unstats.un.org/wiki/display/AIS/AIS+data+at+the+UN+Global+Platform?preview=/57999715/72778218/UNGP%20-%20AIS%20ADSB%20JupyterHubNotebookQueryGuide.pdf#AISdataattheUNGlobalPlatform-Step-by-stepguidelinesforexecutingthesamplescriptsonUNGP)

**cog:** Course over Ground [Degrees]

**draught:** Vessel Draught [Metres]

**eta:** Month, Day, Hour, and Minute of Estimated Time of Arrival in UTC [MMDDHHmm]

**flag_code:** Country of Registration Code

**heading:** Heading [Degrees]

**latitude:** WGS 84 Latitude Coordinate [Decimal Degrees]

**length:** Length of Bow to Main Tower and Main Tower to Stern [Meters]

**longitude:** WGS 84 Longitude Coordinate [Decimal Degrees]

**mmsi:** Maritime Mobile Service Identity (MMSI)

**rot:** Rate of Turn [Degrees / Min]

**sog:** Speed over Ground [Knots]

**vessel_type_code**:* Vessel Type Code

**width:** Length of Port to Main Tower and Main Tower to Starboard [Meters]


```{r}
# Statistics for Numerical features by Vessel Type
data.table(
  ExpNumStat(
    cklist.list,
    by = "GA",
    gp = "vessel_type",
    Qnt = NULL,
    Nlim = 10,
    MesofShape = 2,
    Outlier = TRUE,
    round = 3,
    dcast = FALSE,
    val = NULL
  )
)[order(-TN),
  head(.SD,
       10),
  by = Vname]
```


```{r}
# Statistics for Categorigal features
data.table(
  ExpCTable(
    cklist.list,
    Target = NULL,
    margin = 1,
    clim = 50,
    nlim = 10,
    round = 2,
    bin = 3,
    per = TRUE
  )
)[order(-Frequency),
  head(.SD,
       10),
  by = Variable]
```

## Definitions Categorical Features

**vessel_class:** Class of Vessel (A/B). A =  Targeted at large commercial vessels. B = aimed at lighter commercial and leisure markets. [Link](https://en.wikipedia.org/wiki/Automatic_identification_system)

**vessel_type_cargo:** Vessel Type Cargo

**vessel_type_sub:** Vessel Type Sub-Category

**flag_country:** Country of Registration

**vessel_type_main:** Vessel Type Main

**vessel_type_sub:** Vessel Type Sub-Category

**nav_status:** Navigational Status

**source:** Source of Position Report (S-AIS or T-AIS)

**nav_status_code:** Navigational Status Code

message_type: AIS Position Message type (1,2,3,4,18,19,27). Look up values available [here](https://arundaleais.github.io/docs/ais/ais_message_types.html).

*1: Scheduled position report (Class A shipborne mobile equipment)
*2: Assigned scheduled position report; (Class A shipborne mobile equipment)
*3: Special position report, response to interrogation; (Class A shipborne mobile equipment)
*4: Position, UTC, date and current slot number of base station
*18: Standard position report for Class B shipborne mobile equipment to be used instead of Messages 1, 2, 3
*19: Extended position report for class B shipborne mobile equipment; contains additional static information
*27: Scheduled position report; Class A shipborne mobile equipment outside base station coverage


## Noise Reduction oo

Numerous methods are outlined to reduce noise. Replicate the procedures outlined by [UNSTATS](https://unstats.un.org/wiki/display/AIS/AIS+data+at+the+UN+Global+Platform).


### "Moving Ships" filter Algorithm

From UNSTATS: 

> The distance travelled is calculated in the "Calculate the mount of motion" block by computing the minimum and maximum of latitude and longitudes for all ship positions over the selected period. The differences in latitude and longitude, the deltas, are compared against a predefined threshold values. 

```{r}

```

### "Time in Port" Indicator

From UNSTATS: 

> The "Time in Port" indicator measures the total time spent by all ships within the boundaries of the port monthly over the defined period.

Frequency of calculation: Monthly

1. Calculate time difference between sorted time messages for each MMSI saved as time deltas. If time deltas are > 10800 (3 hours) then 0 the value.
2. Generate Port Index (arbitrary because selection is only for port bounds) + Time Period (Month) + Year


```{r}
# Calculate time difference 
# Sort by mmsi and dth 
cklist.list <- cklist.list[order(cklist.list$dtg),
            `:=` (time_diff_seconds = dtg - shift(dtg)),
            by = mmsi][order(cklist.list$dtg,
                             cklist.list$mmsi)]


# # Test calc
# tt <- cklist.list[vessel_name == "GRINNA2", 
#                   .(dtg, 
#                     month = lubridate::month(dtg), 
#                     year = lubridate::year(dtg),
#                     time_diff_seconds)]
# 
# tta <- tt[, 
#           .(time_diff_seconds = sum(time_diff_seconds, na.rm = TRUE)),
#           by = .(dtg = as.Date(dtg))]
# 
# 
# ttb <- cklist.list[time_diff_seconds > 10800]


# If time difference is greater than 10800 seconds remove
cklist.list[time_diff_seconds >= 10800, 
            time_diff_seconds := 0,
            by = mmsi]



# Create index
cklist.list[,
            index := paste0("ck-tip-",
                                "-",
                                month = lubridate::month(dtg), 
                                "-",
                                year = lubridate::year(dtg))]


tim.ds <- cklist.list[,
                 .(time_in_port_seconds = sum(time_diff_seconds,
                                              na.rm = TRUE)),
                 by = .(index,
                        month = lubridate::month(dtg),
                        year = lubridate::year(dtg),
                        vessel_type,
                        flag_country,
                        vessel_class)][time_in_port_seconds != 0]


# z <- tim.ds[vessel_type %in% c("Cargo"),
#        .(sum_time_mins = sum(time_in_port_seconds, na.rm = TRUE)/60),
#        by = .(year,
#               month)]


# melt.data.table(ki.imts.bot,
#                                id = c("year",
#                                       "month"), measure = c("exports-fob-domestic",
#                                                             "exports-fob-reexport", 
#                                                             "exports-fob-total",
#                                                             "imports-cif",
#                                                             "trade-balance"))

# Time in port dataset
tim.ds <- melt.data.table(tim.ds, 
                          id = c("index",
                                "month",
                                 "year",
                                 "vessel_type",
                                 "flag_country",
                                 "vessel_class"),
                          measure = "time_in_port_seconds")




```


### "Port Traffic" Indicator

From UNSTATS: 

> The "Port Traffic" indicator  captures how many unique ships  have been observed in port based on their reported MMSI. 

Frequency of calculation: Monthly

1. Create time period index using mmsi + port + time period (month)
2. Count Unique 

```{r}
# Create index
cklist.list[,
            index := paste0("ck-ptr",
                                "-",
                                month = lubridate::month(dtg), 
                                "-",
                                year = lubridate::year(dtg))]


ptr.ds <- cklist.list[, 
                  .(unique_count_mmsi = .N), 
                  by = .(index,
                        month = lubridate::month(dtg),
                        year = lubridate::year(dtg),
                        vessel_type,
                        flag_country,
                        vessel_class)]


# z <- ptr.ds[vessel_type %in% c("Cargo"),
#        .(sum  = sum(unique_count_mmsi, na.rm = TRUE)),
#        by = .(year,
#               month)]


ptr.ds <- melt.data.table(ptr.ds, 
                          id = c("index",
                                "month",
                                 "year",
                                 "vessel_type",
                                 "flag_country",
                                 "vessel_class"),
                          measure = "unique_count_mmsi")



tim.ds[, value := as.integer(value)]


ck_ais <- rbind(tim.ds, ptr.ds)


fwrite(ck_ais, "./data/processed/ck_ais.csv")


```




# Read Suva Fiji Islands.

Read the files extracted from UNGP for Lautoka, Fiji Islands. 

```{r eval=FALSE}
# Suva files
file.list <- list.files(path = "./data/external/ais_fj_suva/", 
                        pattern='*.csv')


# Read files in bulk
suva.list <- lapply(paste0("./data/external/ais_fj_suva/",
                           file.list),
                  fread)


# turn into one table 
suva.list <- rbindlist(suva.list)


head(suva.list)
```

## Exploration 

1. Convert dtg and eta to as.POSIXct(x, tz = "", ...)

```{r eval=FALSE}
# Change from char to posixct 
suva.list[,
            `:=` (dtg = gsub("T",
                             " ",
                             dtg
                             )
                  )][,
                     `:=` (dtg = gsub(".000Z",
                             "",
                             dtg
                             )
                           )]


suva.list[,
            `:=` (dtg = strptime(dtg, "%Y-%m-%d %H:%M:%S")
                  )]


# check summary 
suva.list[,
            summary(dtg)]
```


```{r eval=FALSE}
# Check out dataset quality
ExpData(
  data = suva.list,
  type = 1
  )
```


```{r eval=FALSE}
# Check out data feature quality
ExpData(
  data = suva.list,
  type = 2
  )
```


```{r eval=FALSE}
# Statistics for Numerical features 
data.table(
  ExpNumStat(
    suva.list,
    by = "A",
    gp = NULL,
    Qnt = NULL,
    Nlim = 10,
    MesofShape = 2,
    Outlier = TRUE,
    round = 3,
    dcast = FALSE,
    val = NULL
  )
)
```


```{r eval=FALSE}
# Statistics for Numerical features by Vessel Type
data.table(
  ExpNumStat(
    suva.list,
    by = "GA",
    gp = "vessel_type",
    Qnt = NULL,
    Nlim = 10,
    MesofShape = 2,
    Outlier = TRUE,
    round = 3,
    dcast = FALSE,
    val = NULL
  )
)[order(-TN),
  head(.SD,
       10),
  by = Vname]
```


```{r eval=FALSE}
# Statistics for Categorigal features
data.table(
  ExpCTable(
    suva.list,
    Target = NULL,
    margin = 1,
    clim = 50,
    nlim = 10,
    round = 2,
    bin = 3,
    per = TRUE
  )
)[order(-Frequency),
  head(.SD,
       10),
  by = Variable]
```

## Noise Reduction 

Numerous methods are outlined to reduce noise. Replicate the procedures outlined by [UNSTATS](https://unstats.un.org/wiki/display/AIS/AIS+data+at+the+UN+Global+Platform).


### "Moving Ships" filter Algorithm

From UNSTATS: 

> The distance travelled is calculated in the "Calculate the mount of motion" block by computing the minimum and maximum of latitude and longitudes for all ship positions over the selected period. The differences in latitude and longitude, the deltas, are compared against a predefined threshold values. 

```{r eval=FALSE}

```

### "Time in Port" Indicator

From UNSTATS: 

> The "Time in Port" indicator measures the total time spent by all ships within the boundaries of the port monthly over the defined period.

Frequency of calculation: Monthly

1. Calculate time difference between sorted time messages for each MMSI saved as time deltas. 
2. Generate Port Index (arbitrary because selection is only for port bounds) + Time Period (Month) + Year


```{r eval=FALSE}
# Calculate time difference 
# Sort by mmsi and dth 
suva.list <- suva.list[order(suva.list$dtg),
            `:=` (time_diff_seconds = dtg - shift(dtg)),
            by = mmsi][order(suva.list$dtg,
                             suva.list$mmsi)]


# If time difference is greater than 10800 seconds remove
suva.list[time_diff_seconds >= 10800, 
            time_diff_seconds := 0,
            by = mmsi]


# Create index
suva.list[,
            index := paste0("fj-suva-tip-",
                                "-",
                                month = lubridate::month(dtg), 
                                "-",
                                year = lubridate::year(dtg))]


tim.ds <- suva.list[,
                 .(time_in_port_seconds = sum(time_diff_seconds,
                                              na.rm = TRUE)),
                 by = .(index,
                        month = lubridate::month(dtg),
                        year = lubridate::year(dtg),
                        vessel_type,
                        flag_country,
                        vessel_class)][time_in_port_seconds != 0]


# z <- tim.ds[,
#        .(sum_time_mins = sum(time_in_port_seconds, na.rm = TRUE)/60),
#        by = .(year,
#               month)]


# melt.data.table(ki.imts.bot,
#                                id = c("year",
#                                       "month"), measure = c("exports-fob-domestic",
#                                                             "exports-fob-reexport", 
#                                                             "exports-fob-total",
#                                                             "imports-cif",
#                                                             "trade-balance"))


tim.ds <- melt.data.table(tim.ds, 
                          id = c("index",
                                "month",
                                 "year",
                                 "vessel_type",
                                 "flag_country",
                                 "vessel_class"),
                          measure = "time_in_port_seconds")




```


### "Port Traffic" Indicator

From UNSTATS: 

> The "Port Traffic" indicator  captures how many unique ships  have been observed in port based on their reported MMSI. 

Frequency of calculation: Monthly

1. Create time period index using mmsi + port + time period (month)
2. Count Unique 

```{r eval=FALSE}
# Create index
suva.list[,
            index := paste0("fj-suva-ptr",
                                "-",
                                month = lubridate::month(dtg), 
                                "-",
                                year = lubridate::year(dtg))]


ptr.ds <- suva.list[, 
                  .(unique_count_mmsi = .N), 
                  by = .(index,
                        month = lubridate::month(dtg),
                        year = lubridate::year(dtg),
                        vessel_type,
                        flag_country,
                        vessel_class)]


# z <- ptr.ds[,
#        .(sum  = sum(unique_count_mmsi, na.rm = TRUE)),
#        by = .(year,
#               month)]


ptr.ds <- melt.data.table(ptr.ds, 
                          id = c("index",
                                "month",
                                 "year",
                                 "vessel_type",
                                 "flag_country",
                                 "vessel_class"),
                          measure = "unique_count_mmsi")



tim.ds[, value := as.integer(value)]


fj_suva_ais <- rbind(tim.ds, ptr.ds)


fwrite(fj_suva_ais, "./data/processed/fj_suva_ais.csv")


```



# Read Lautoka Fiji Islands

Read the files extracted from UNGP for Lautoka, Fiji Islands. 

```{r eval=FALSE}
# Suva files
file.list <- list.files(path = "./data/external/ais_fj_lautoka/", 
                        pattern='*.csv')


# Read files in bulk
lautoka.list <- lapply(paste0("./data/external/ais_fj_lautoka/",
                           file.list),
                  fread)


# turn into one table 
lautoka.list <- rbindlist(lautoka.list)


head(lautoka.list)
```

## Exploration 

1. Convert dtg and eta to as.POSIXct(x, tz = "", ...)

```{r eval=FALSE}
# Change from char to posixct 
lautoka.list[,
            `:=` (dtg = gsub("T",
                             " ",
                             dtg
                             )
                  )][,
                     `:=` (dtg = gsub(".000Z",
                             "",
                             dtg
                             )
                           )]


lautoka.list[,
            `:=` (dtg = strptime(dtg, "%Y-%m-%d %H:%M:%S")
                  )]


# check summary 
lautoka.list[,
            summary(dtg)]
```


```{r eval=FALSE}
# Check out dataset quality
ExpData(
  data = lautoka.list,
  type = 1
  )
```


```{r eval=FALSE}
# Check out data feature quality
ExpData(
  data = lautoka.list,
  type = 2
  )
```


```{r eval=FALSE}
# Statistics for Numerical features 
data.table(
  ExpNumStat(
    lautoka.list,
    by = "A",
    gp = NULL,
    Qnt = NULL,
    Nlim = 10,
    MesofShape = 2,
    Outlier = TRUE,
    round = 3,
    dcast = FALSE,
    val = NULL
  )
)
```


```{r eval=FALSE}
# Statistics for Numerical features by Vessel Type
data.table(
  ExpNumStat(
    lautoka.list,
    by = "GA",
    gp = "vessel_type",
    Qnt = NULL,
    Nlim = 10,
    MesofShape = 2,
    Outlier = TRUE,
    round = 3,
    dcast = FALSE,
    val = NULL
  )
)[order(-TN),
  head(.SD,
       10),
  by = Vname]
```


```{r eval=FALSE}
# Statistics for Categorigal features
data.table(
  ExpCTable(
    lautoka.list,
    Target = NULL,
    margin = 1,
    clim = 50,
    nlim = 10,
    round = 2,
    bin = 3,
    per = TRUE
  )
)[order(-Frequency),
  head(.SD,
       10),
  by = Variable]
```

## Noise Reduction 

Numerous methods are outlined to reduce noise. Replicate the procedures outlined by [UNSTATS](https://unstats.un.org/wiki/display/AIS/AIS+data+at+the+UN+Global+Platform).


### "Moving Ships" filter Algorithm

From UNSTATS: 

> The distance travelled is calculated in the "Calculate the mount of motion" block by computing the minimum and maximum of latitude and longitudes for all ship positions over the selected period. The differences in latitude and longitude, the deltas, are compared against a predefined threshold values. 

```{reval=FALSE}

```

### "Time in Port" Indicator

From UNSTATS: 

> The "Time in Port" indicator measures the total time spent by all ships within the boundaries of the port monthly over the defined period.

Frequency of calculation: Monthly

1. Calculate time difference between sorted time messages for each MMSI saved as time deltas. 
2. Generate Port Index (arbitrary because selection is only for port bounds) + Time Period (Month) + Year


```{r eval=FALSE}
# Calculate time difference 
# Sort by mmsi and dth 
lautoka.list <- lautoka.list[order(lautoka.list$dtg),
            `:=` (time_diff_seconds = dtg - shift(dtg)),
            by = mmsi][order(lautoka.list$dtg,
                             lautoka.list$mmsi)]


# If time difference is greater than 10800 seconds remove
lautoka.list[time_diff_seconds >= 10800, 
            time_diff_seconds := 0,
            by = mmsi]


# Create index
lautoka.list[,
            index := paste0("fj-ltka-tip-",
                                "-",
                                month = lubridate::month(dtg), 
                                "-",
                                year = lubridate::year(dtg))]


tim.ds <- lautoka.list[,
                 .(time_in_port_seconds = sum(time_diff_seconds,
                                              na.rm = TRUE)),
                 by = .(index,
                        month = lubridate::month(dtg),
                        year = lubridate::year(dtg),
                        vessel_type,
                        flag_country,
                        vessel_class)][time_in_port_seconds != 0]


# z <- tim.ds[,
#        .(sum_time_mins = sum(time_in_port_seconds, na.rm = TRUE)/60),
#        by = .(year,
#               month)]


# melt.data.table(ki.imts.bot,
#                                id = c("year",
#                                       "month"), measure = c("exports-fob-domestic",
#                                                             "exports-fob-reexport", 
#                                                             "exports-fob-total",
#                                                             "imports-cif",
#                                                             "trade-balance"))


tim.ds <- melt.data.table(tim.ds, 
                          id = c("index",
                                "month",
                                 "year",
                                 "vessel_type",
                                 "flag_country",
                                 "vessel_class"),
                          measure = "time_in_port_seconds")




```


### "Port Traffic" Indicator

From UNSTATS: 

> The "Port Traffic" indicator  captures how many unique ships  have been observed in port based on their reported MMSI. 

Frequency of calculation: Monthly

1. Create time period index using mmsi + port + time period (month)
2. Count Unique 

```{r eval=FALSE}
# Create index
lautoka.list[,
            index := paste0("fj-ltka-ptr",
                                "-",
                                month = lubridate::month(dtg), 
                                "-",
                                year = lubridate::year(dtg))]


ptr.ds <- lautoka.list[, 
                  .(unique_count_mmsi = .N), 
                  by = .(index,
                        month = lubridate::month(dtg),
                        year = lubridate::year(dtg),
                        vessel_type,
                        flag_country,
                        vessel_class)]


# z <- ptr.ds[,
#        .(sum  = sum(unique_count_mmsi, na.rm = TRUE)),
#        by = .(year,
#               month)]


ptr.ds <- melt.data.table(ptr.ds, 
                          id = c("index",
                                "month",
                                 "year",
                                 "vessel_type",
                                 "flag_country",
                                 "vessel_class"),
                          measure = "unique_count_mmsi")



tim.ds[, value := as.integer(value)]


fj_ltka_ais <- rbind(tim.ds, ptr.ds)


fwrite(fj_ltka_ais, "./data/processed/fj_ltka_ais.csv")


```




# Read Noro Solomon Islands

Read the files extracted from UNGP for Noro, Solomon Islands. 

```{r eval=FALSE}
# Noro files
file.list <- list.files(path = "./data/external/ais_sl_noro/", 
                        pattern='*.csv')


# Read files in bulk
noro.list <- lapply(paste0("./data/external/ais_sl_noro/",
                           file.list),
                  fread)


# turn into one table 
noro.list <- rbindlist(noro.list)


head(noro.list)
```

## Exploration 

1. Convert dtg and eta to as.POSIXct(x, tz = "", ...)

```{r eval=FALSE}
# Change from char to posixct 
noro.list[,
            `:=` (dtg = gsub("T",
                             " ",
                             dtg
                             )
                  )][,
                     `:=` (dtg = gsub(".000Z",
                             "",
                             dtg
                             )
                           )]


noro.list[,
            `:=` (dtg = strptime(dtg, "%Y-%m-%d %H:%M:%S")
                  )]


# check summary 
noro.list[,
            summary(dtg)]
```


```{r eval=FALSE}
# Check out dataset quality
ExpData(
  data = noro.list,
  type = 1
  )
```


```{r eval=FALSE}
# Check out data feature quality
ExpData(
  data = noro.list,
  type = 2
  )
```


```{r eval=FALSE}
# Statistics for Numerical features 
data.table(
  ExpNumStat(
    noro.list,
    by = "A",
    gp = NULL,
    Qnt = NULL,
    Nlim = 10,
    MesofShape = 2,
    Outlier = TRUE,
    round = 3,
    dcast = FALSE,
    val = NULL
  )
)
```


```{r eval=FALSE}
# Statistics for Numerical features by Vessel Type
data.table(
  ExpNumStat(
    noro.list,
    by = "GA",
    gp = "vessel_type",
    Qnt = NULL,
    Nlim = 10,
    MesofShape = 2,
    Outlier = TRUE,
    round = 3,
    dcast = FALSE,
    val = NULL
  )
)[order(-TN),
  head(.SD,
       10),
  by = Vname]
```


```{r eval=FALSE}
# Statistics for Categorigal features
data.table(
  ExpCTable(
    noro.list,
    Target = NULL,
    margin = 1,
    clim = 50,
    nlim = 10,
    round = 2,
    bin = 3,
    per = TRUE
  )
)[order(-Frequency),
  head(.SD,
       10),
  by = Variable]
```

## Noise Reduction 

Numerous methods are outlined to reduce noise. Replicate the procedures outlined by [UNSTATS](https://unstats.un.org/wiki/display/AIS/AIS+data+at+the+UN+Global+Platform).


### "Moving Ships" filter Algorithm

From UNSTATS: 

> The distance travelled is calculated in the "Calculate the mount of motion" block by computing the minimum and maximum of latitude and longitudes for all ship positions over the selected period. The differences in latitude and longitude, the deltas, are compared against a predefined threshold values. 

```{r eval=FALSE}

```

### "Time in Port" Indicator

From UNSTATS: 

> The "Time in Port" indicator measures the total time spent by all ships within the boundaries of the port monthly over the defined period.

Frequency of calculation: Monthly

1. Calculate time difference between sorted time messages for each MMSI saved as time deltas. 
2. Generate Port Index (arbitrary because selection is only for port bounds) + Time Period (Month) + Year


```{r eval=FALSE}
# Calculate time difference 
# Sort by mmsi and dth 
noro.list <- noro.list[order(noro.list$dtg),
            `:=` (time_diff_seconds = dtg - shift(dtg)),
            by = mmsi][order(noro.list$dtg,
                             noro.list$mmsi)]


# If time difference is greater than 10800 seconds remove
noro.list[time_diff_seconds >= 10800, 
            time_diff_seconds := 0,
            by = mmsi]


# Create index
noro.list[,
            index := paste0("sl-noro-tip-",
                                "-",
                                month = lubridate::month(dtg), 
                                "-",
                                year = lubridate::year(dtg))]


tim.ds <- noro.list[,
                 .(time_in_port_seconds = sum(time_diff_seconds,
                                              na.rm = TRUE)),
                 by = .(index,
                        month = lubridate::month(dtg),
                        year = lubridate::year(dtg),
                        vessel_type,
                        flag_country,
                        vessel_class)][time_in_port_seconds != 0]


# z <- tim.ds[,
#        .(sum_time_mins = sum(time_in_port_seconds, na.rm = TRUE)/60),
#        by = .(year,
#               month)]


# melt.data.table(ki.imts.bot,
#                                id = c("year",
#                                       "month"), measure = c("exports-fob-domestic",
#                                                             "exports-fob-reexport", 
#                                                             "exports-fob-total",
#                                                             "imports-cif",
#                                                             "trade-balance"))


tim.ds <- melt.data.table(tim.ds, 
                          id = c("index",
                                "month",
                                 "year",
                                 "vessel_type",
                                 "flag_country",
                                 "vessel_class"),
                          measure = "time_in_port_seconds")




```


### "Port Traffic" Indicator

From UNSTATS: 

> The "Port Traffic" indicator  captures how many unique ships  have been observed in port based on their reported MMSI. 

Frequency of calculation: Monthly

1. Create time period index using mmsi + port + time period (month)
2. Count Unique 

```{r eval=FALSE}
# Create index
noro.list[,
            index := paste0("sl-noro-ptr",
                                "-",
                                month = lubridate::month(dtg), 
                                "-",
                                year = lubridate::year(dtg))]


ptr.ds <- noro.list[, 
                  .(unique_count_mmsi = .N), 
                  by = .(index,
                        month = lubridate::month(dtg),
                        year = lubridate::year(dtg),
                        vessel_type,
                        flag_country,
                        vessel_class)]


# z <- ptr.ds[,
#        .(sum  = sum(unique_count_mmsi, na.rm = TRUE)),
#        by = .(year,
#               month)]


ptr.ds <- melt.data.table(ptr.ds, 
                          id = c("index",
                                "month",
                                 "year",
                                 "vessel_type",
                                 "flag_country",
                                 "vessel_class"),
                          measure = "unique_count_mmsi")



tim.ds[, value := as.integer(value)]


sl_noro_ais <- rbind(tim.ds, ptr.ds)


fwrite(sl_noro_ais, "./data/processed/sl_noro_ais.csv")


```





# Read Port Vila Vanuatu

Read the files extracted from UNGP for Port Vila, Vanuatu. 

```{r eval=FALSE}
# port.v.list files
file.list <- list.files(path = "./data/external/ais_vn_port_vila/", 
                        pattern='*.csv')


# Read files in bulk
port.v.list <- lapply(paste0("./data/external/ais_vn_port_vila/",
                           file.list),
                  fread)


# turn into one table 
port.v.list <- rbindlist(port.v.list)


head(port.v.list)
```

## Exploration 

1. Convert dtg and eta to as.POSIXct(x, tz = "", ...)

```{r eval=FALSE}
# Change from char to posixct 
port.v.list[,
            `:=` (dtg = gsub("T",
                             " ",
                             dtg
                             )
                  )][,
                     `:=` (dtg = gsub(".000Z",
                             "",
                             dtg
                             )
                           )]


port.v.list[,
            `:=` (dtg = strptime(dtg, "%Y-%m-%d %H:%M:%S")
                  )]


# check summary 
port.v.list[,
            summary(dtg)]
```


```{r eval=FALSE}
# Check out dataset quality
ExpData(
  data = port.v.list,
  type = 1
  )
```


```{r eval=FALSE}
# Check out data feature quality
ExpData(
  data = port.v.list,
  type = 2
  )
```


```{r eval=FALSE}
# Statistics for Numerical features 
data.table(
  ExpNumStat(
    port.v.list,
    by = "A",
    gp = NULL,
    Qnt = NULL,
    Nlim = 10,
    MesofShape = 2,
    Outlier = TRUE,
    round = 3,
    dcast = FALSE,
    val = NULL
  )
)
```


```{r eval=FALSE}
# Statistics for Numerical features by Vessel Type
data.table(
  ExpNumStat(
    port.v.list,
    by = "GA",
    gp = "vessel_type",
    Qnt = NULL,
    Nlim = 10,
    MesofShape = 2,
    Outlier = TRUE,
    round = 3,
    dcast = FALSE,
    val = NULL
  )
)[order(-TN),
  head(.SD,
       10),
  by = Vname]
```


```{r eval=FALSE}
# Statistics for Categorigal features
data.table(
  ExpCTable(
    port.v.list,
    Target = NULL,
    margin = 1,
    clim = 50,
    nlim = 10,
    round = 2,
    bin = 3,
    per = TRUE
  )
)[order(-Frequency),
  head(.SD,
       10),
  by = Variable]
```

## Noise Reduction 

Numerous methods are outlined to reduce noise. Replicate the procedures outlined by [UNSTATS](https://unstats.un.org/wiki/display/AIS/AIS+data+at+the+UN+Global+Platform).


### "Moving Ships" filter Algorithm

From UNSTATS: 

> The distance travelled is calculated in the "Calculate the mount of motion" block by computing the minimum and maximum of latitude and longitudes for all ship positions over the selected period. The differences in latitude and longitude, the deltas, are compared against a predefined threshold values. 

```{r eval=FALSE}

```

### "Time in Port" Indicator

From UNSTATS: 

> The "Time in Port" indicator measures the total time spent by all ships within the boundaries of the port monthly over the defined period.

Frequency of calculation: Monthly

1. Calculate time difference between sorted time messages for each MMSI saved as time deltas. 
2. Generate Port Index (arbitrary because selection is only for port bounds) + Time Period (Month) + Year


```{r eval=FALSE}
# Calculate time difference 
# Sort by mmsi and dth 
port.v.list <- port.v.list[order(port.v.list$dtg),
            `:=` (time_diff_seconds = dtg - shift(dtg)),
            by = mmsi][order(port.v.list$dtg,
                             port.v.list$mmsi)]


# If time difference is greater than 10800 seconds remove
port.v.list[time_diff_seconds >= 10800, 
            time_diff_seconds := 0,
            by = mmsi]


# Create index
port.v.list[,
            index := paste0("vn-ptvl-tip-",
                                "-",
                                month = lubridate::month(dtg), 
                                "-",
                                year = lubridate::year(dtg))]


tim.ds <- port.v.list[,
                 .(time_in_port_seconds = sum(time_diff_seconds,
                                              na.rm = TRUE)),
                 by = .(index,
                        month = lubridate::month(dtg),
                        year = lubridate::year(dtg),
                        vessel_type,
                        flag_country,
                        vessel_class)][time_in_port_seconds != 0]


# z <- tim.ds[,
#        .(sum_time_mins = sum(time_in_port_seconds, na.rm = TRUE)/60),
#        by = .(year,
#               month)]


# melt.data.table(ki.imts.bot,
#                                id = c("year",
#                                       "month"), measure = c("exports-fob-domestic",
#                                                             "exports-fob-reexport", 
#                                                             "exports-fob-total",
#                                                             "imports-cif",
#                                                             "trade-balance"))


tim.ds <- melt.data.table(tim.ds, 
                          id = c("index",
                                "month",
                                 "year",
                                 "vessel_type",
                                 "flag_country",
                                 "vessel_class"),
                          measure = "time_in_port_seconds")




```


### "Port Traffic" Indicator

From UNSTATS: 

> The "Port Traffic" indicator  captures how many unique ships  have been observed in port based on their reported MMSI. 

Frequency of calculation: Monthly

1. Create time period index using mmsi + port + time period (month)
2. Count Unique 

```{r eval=FALSE}
# Create index
port.v.list[,
            index := paste0("vn-ptvl-ptr",
                                "-",
                                month = lubridate::month(dtg), 
                                "-",
                                year = lubridate::year(dtg))]


ptr.ds <- port.v.list[, 
                  .(unique_count_mmsi = .N), 
                  by = .(index,
                        month = lubridate::month(dtg),
                        year = lubridate::year(dtg),
                        vessel_type,
                        flag_country,
                        vessel_class)]


# z <- ptr.ds[,
#        .(sum  = sum(unique_count_mmsi, na.rm = TRUE)),
#        by = .(year,
#               month)]


ptr.ds <- melt.data.table(ptr.ds, 
                          id = c("index",
                                "month",
                                 "year",
                                 "vessel_type",
                                 "flag_country",
                                 "vessel_class"),
                          measure = "unique_count_mmsi")



tim.ds[, value := as.integer(value)]


vn_pv_ais <- rbind(tim.ds, ptr.ds)


fwrite(vn_pv_ais, "./data/processed/vn_portvila_ais.csv")


```




# Read Luganville Vanuatu 

Read the files extracted from UNGP for Luganville, Vanuatu. 

```{r eval=FALSE}
# lugv.list files
file.list <- list.files(path = "./data/external/ais_vn_luganville/", 
                        pattern='*.csv')


# Read files in bulk
lugv.list <- lapply(paste0("./data/external/ais_vn_luganville/",
                           file.list),
                  fread)


# turn into one table 
lugv.list <- rbindlist(lugv.list)


head(lugv.list)
```

## Exploration 

1. Convert dtg and eta to as.POSIXct(x, tz = "", ...)

```{r eval=FALSE}
# Change from char to posixct 
lugv.list[,
            `:=` (dtg = gsub("T",
                             " ",
                             dtg
                             )
                  )][,
                     `:=` (dtg = gsub(".000Z",
                             "",
                             dtg
                             )
                           )]


lugv.list[,
            `:=` (dtg = strptime(dtg, "%Y-%m-%d %H:%M:%S")
                  )]


# check summary 
lugv.list[,
            summary(dtg)]
```


```{r eval=FALSE}
# Check out dataset quality
ExpData(
  data = lugv.list,
  type = 1
  )
```


```{r eval=FALSE}
# Check out data feature quality
ExpData(
  data = lugv.list,
  type = 2
  )
```


```{r eval=FALSE}
# Statistics for Numerical features 
data.table(
  ExpNumStat(
    lugv.list,
    by = "A",
    gp = NULL,
    Qnt = NULL,
    Nlim = 10,
    MesofShape = 2,
    Outlier = TRUE,
    round = 3,
    dcast = FALSE,
    val = NULL
  )
)
```


```{r eval=FALSE}
# Statistics for Numerical features by Vessel Type
data.table(
  ExpNumStat(
    lugv.list,
    by = "GA",
    gp = "vessel_type",
    Qnt = NULL,
    Nlim = 10,
    MesofShape = 2,
    Outlier = TRUE,
    round = 3,
    dcast = FALSE,
    val = NULL
  )
)[order(-TN),
  head(.SD,
       10),
  by = Vname]
```


```{r eval=FALSE}
# Statistics for Categorigal features
data.table(
  ExpCTable(
    lugv.list,
    Target = NULL,
    margin = 1,
    clim = 50,
    nlim = 10,
    round = 2,
    bin = 3,
    per = TRUE
  )
)[order(-Frequency),
  head(.SD,
       10),
  by = Variable]
```

## Noise Reduction 

Numerous methods are outlined to reduce noise. Replicate the procedures outlined by [UNSTATS](https://unstats.un.org/wiki/display/AIS/AIS+data+at+the+UN+Global+Platform).


### "Moving Ships" filter Algorithm

From UNSTATS: 

> The distance travelled is calculated in the "Calculate the mount of motion" block by computing the minimum and maximum of latitude and longitudes for all ship positions over the selected period. The differences in latitude and longitude, the deltas, are compared against a predefined threshold values. 

```{r eval=FALSE}

```

### "Time in Port" Indicator

From UNSTATS: 

> The "Time in Port" indicator measures the total time spent by all ships within the boundaries of the port monthly over the defined period.

Frequency of calculation: Monthly

1. Calculate time difference between sorted time messages for each MMSI saved as time deltas. 
2. Generate Port Index (arbitrary because selection is only for port bounds) + Time Period (Month) + Year


```{r eval=FALSE}
# Calculate time difference 
# Sort by mmsi and dth 
lugv.list <- lugv.list[order(lugv.list$dtg),
            `:=` (time_diff_seconds = dtg - shift(dtg)),
            by = mmsi][order(lugv.list$dtg,
                             lugv.list$mmsi)]


# If time difference is greater than 10800 seconds remove
lugv.list[time_diff_seconds >= 10800, 
            time_diff_seconds := 0,
            by = mmsi]


# Create index
lugv.list[,
            index := paste0("vn-lgvl-tip-",
                                "-",
                                month = lubridate::month(dtg), 
                                "-",
                                year = lubridate::year(dtg))]


tim.ds <- lugv.list[,
                 .(time_in_port_seconds = sum(time_diff_seconds,
                                              na.rm = TRUE)),
                 by = .(index,
                        month = lubridate::month(dtg),
                        year = lubridate::year(dtg),
                        vessel_type,
                        flag_country,
                        vessel_class)][time_in_port_seconds != 0]


# z <- tim.ds[,
#        .(sum_time_mins = sum(time_in_port_seconds, na.rm = TRUE)/60),
#        by = .(year,
#               month)]


# melt.data.table(ki.imts.bot,
#                                id = c("year",
#                                       "month"), measure = c("exports-fob-domestic",
#                                                             "exports-fob-reexport", 
#                                                             "exports-fob-total",
#                                                             "imports-cif",
#                                                             "trade-balance"))


tim.ds <- melt.data.table(tim.ds, 
                          id = c("index",
                                "month",
                                 "year",
                                 "vessel_type",
                                 "flag_country",
                                 "vessel_class"),
                          measure = "time_in_port_seconds")




```


### "Port Traffic" Indicator

From UNSTATS: 

> The "Port Traffic" indicator  captures how many unique ships  have been observed in port based on their reported MMSI. 

Frequency of calculation: Monthly

1. Create time period index using mmsi + port + time period (month)
2. Count Unique 

```{r eval=FALSE}
# Create index
lugv.list[,
            index := paste0("vn-lgvl-ptr",
                                "-",
                                month = lubridate::month(dtg), 
                                "-",
                                year = lubridate::year(dtg))]


ptr.ds <- lugv.list[, 
                  .(unique_count_mmsi = .N), 
                  by = .(index,
                        month = lubridate::month(dtg),
                        year = lubridate::year(dtg),
                        vessel_type,
                        flag_country,
                        vessel_class)]


# z <- ptr.ds[,
#        .(sum  = sum(unique_count_mmsi, na.rm = TRUE)),
#        by = .(year,
#               month)]


ptr.ds <- melt.data.table(ptr.ds, 
                          id = c("index",
                                "month",
                                 "year",
                                 "vessel_type",
                                 "flag_country",
                                 "vessel_class"),
                          measure = "unique_count_mmsi")



tim.ds[, value := as.integer(value)]


vn_lv_ais <- rbind(tim.ds, ptr.ds)


fwrite(vn_lv_ais, "./data/processed/vn_lugv_ais.csv")


```





# Read Honoira Solomon Islands

Read the files extracted from UNGP for Honiora, Solomon Islands. 

```{r eval=FALSE}
# Honiora files
file.list <- list.files(path = "./data/external/ais_sl_honiora/", 
                        pattern='*.csv')


# Read files in bulk
honiora.list <- lapply(paste0("./data/external/ais_sl_honiora/",
                           file.list),
                  fread)


# turn into one table 
honiora.list <- rbindlist(honiora.list)


head(honiora.list)
```

## Exploration 

1. Convert dtg and eta to as.POSIXct(x, tz = "", ...)

```{r eval=FALSE}
# Change from char to posixct 
honiora.list[,
            `:=` (dtg = gsub("T",
                             " ",
                             dtg
                             )
                  )][,
                     `:=` (dtg = gsub(".000Z",
                             "",
                             dtg
                             )
                           )]


honiora.list[,
            `:=` (dtg = strptime(dtg, "%Y-%m-%d %H:%M:%S")
                  )]


# check summary 
honiora.list[,
            summary(dtg)]
```


```{r eval=FALSE}
# Check out dataset quality
ExpData(
  data = honiora.list,
  type = 1
  )
```


```{r eval=FALSE}
# Check out data feature quality
ExpData(
  data = honiora.list,
  type = 2
  )
```


```{r eval=FALSE}
# Statistics for Numerical features 
data.table(
  ExpNumStat(
    honiora.list,
    by = "A",
    gp = NULL,
    Qnt = NULL,
    Nlim = 10,
    MesofShape = 2,
    Outlier = TRUE,
    round = 3,
    dcast = FALSE,
    val = NULL
  )
)
```


```{r eval=FALSE}
# Statistics for Numerical features by Vessel Type
data.table(
  ExpNumStat(
    honiora.list,
    by = "GA",
    gp = "vessel_type",
    Qnt = NULL,
    Nlim = 10,
    MesofShape = 2,
    Outlier = TRUE,
    round = 3,
    dcast = FALSE,
    val = NULL
  )
)[order(-TN),
  head(.SD,
       10),
  by = Vname]
```


```{r eval=FALSE}
# Statistics for Categorigal features
data.table(
  ExpCTable(
    honiora.list,
    Target = NULL,
    margin = 1,
    clim = 50,
    nlim = 10,
    round = 2,
    bin = 3,
    per = TRUE
  )
)[order(-Frequency),
  head(.SD,
       10),
  by = Variable]
```

## Noise Reduction 

Numerous methods are outlined to reduce noise. Replicate the procedures outlined by [UNSTATS](https://unstats.un.org/wiki/display/AIS/AIS+data+at+the+UN+Global+Platform).


### "Moving Ships" filter Algorithm

From UNSTATS: 

> The distance travelled is calculated in the "Calculate the mount of motion" block by computing the minimum and maximum of latitude and longitudes for all ship positions over the selected period. The differences in latitude and longitude, the deltas, are compared against a predefined threshold values. 

```{r eval=FALSE}

```

### "Time in Port" Indicator

From UNSTATS: 

> The "Time in Port" indicator measures the total time spent by all ships within the boundaries of the port monthly over the defined period.

Frequency of calculation: Monthly

1. Calculate time difference between sorted time messages for each MMSI saved as time deltas. 
2. Generate Port Index (arbitrary because selection is only for port bounds) + Time Period (Month) + Year


```{r eval=FALSE}
# Calculate time difference 
# Sort by mmsi and dth 
honiora.list <- honiora.list[order(honiora.list$dtg),
            `:=` (time_diff_seconds = dtg - shift(dtg)),
            by = mmsi][order(honiora.list$dtg,
                             honiora.list$mmsi)]


# If time difference is greater than 10800 seconds remove
honiora.list[time_diff_seconds >= 10800, 
            time_diff_seconds := 0,
            by = mmsi]


# Create index
honiora.list[,
            index := paste0("sl-honi-tip-",
                                "-",
                                month = lubridate::month(dtg), 
                                "-",
                                year = lubridate::year(dtg))]


tim.ds <- honiora.list[,
                 .(time_in_port_seconds = sum(time_diff_seconds,
                                              na.rm = TRUE)),
                 by = .(index,
                        month = lubridate::month(dtg),
                        year = lubridate::year(dtg),
                        vessel_type,
                        flag_country,
                        vessel_class)][time_in_port_seconds != 0]


# z <- tim.ds[,
#        .(sum_time_mins = sum(time_in_port_seconds, na.rm = TRUE)/60),
#        by = .(year,
#               month)]


# melt.data.table(ki.imts.bot,
#                                id = c("year",
#                                       "month"), measure = c("exports-fob-domestic",
#                                                             "exports-fob-reexport", 
#                                                             "exports-fob-total",
#                                                             "imports-cif",
#                                                             "trade-balance"))


tim.ds <- melt.data.table(tim.ds, 
                          id = c("index",
                                "month",
                                 "year",
                                 "vessel_type",
                                 "flag_country",
                                 "vessel_class"),
                          measure = "time_in_port_seconds")




```


### "Port Traffic" Indicator

From UNSTATS: 

> The "Port Traffic" indicator  captures how many unique ships  have been observed in port based on their reported MMSI. 

Frequency of calculation: Monthly

1. Create time period index using mmsi + port + time period (month)
2. Count Unique 

```{r eval=FALSE}
# Create index
honiora.list[,
            index := paste0("sl-honi-ptr",
                                "-",
                                month = lubridate::month(dtg), 
                                "-",
                                year = lubridate::year(dtg))]


ptr.ds <- honiora.list[, 
                  .(unique_count_mmsi = .N), 
                  by = .(index,
                        month = lubridate::month(dtg),
                        year = lubridate::year(dtg),
                        vessel_type,
                        flag_country,
                        vessel_class)]


# z <- ptr.ds[,
#        .(sum  = sum(unique_count_mmsi, na.rm = TRUE)),
#        by = .(year,
#               month)]


ptr.ds <- melt.data.table(ptr.ds, 
                          id = c("index",
                                "month",
                                 "year",
                                 "vessel_type",
                                 "flag_country",
                                 "vessel_class"),
                          measure = "unique_count_mmsi")



tim.ds[, value := as.integer(value)]


sl_honiora_ais <- rbind(tim.ds, ptr.ds)


fwrite(sl_honiora_ais, "./data/processed/sl_honiora_ais.csv")


```


# Read Kiribati 
Read the files extracted from UNGP for Betio, Kiribati. 

```{r eval=FALSE}
# betio.v.list files
file.list <- list.files(path = "./data/external/ais_ki_betio/", 
                        pattern='*.csv')


# Read files in bulk
betio.v.list <- lapply(paste0("./data/external/ais_ki_betio/",
                           file.list),
                  fread)


# turn into one table 
betio.v.list <- rbindlist(betio.v.list)


betio.v.list <- betio.v.list[,1:28]


head(betio.v.list)
```

## Exploration 

1. Convert dtg and eta to as.POSIXct(x, tz = "", ...)

```{r eval=FALSE}
# Change from char to posixct 
betio.v.list[,
            `:=` (dtg = gsub("T",
                             " ",
                             dtg
                             )
                  )][,
                     `:=` (dtg = gsub(".000Z",
                             "",
                             dtg
                             )
                           )]


betio.v.list[,
            `:=` (dtg = strptime(dtg, "%Y-%m-%d %H:%M:%S")
                  )]


# check summary 
betio.v.list[,
            summary(dtg)]
```


```{r eval=FALSE}
# Check out dataset quality
ExpData(
  data = betio.v.list,
  type = 1
  )
```


```{r eval=FALSE}
# Check out data feature quality
ExpData(
  data = betio.v.list,
  type = 2
  )
```


```{r eval=FALSE}
# Statistics for Numerical features 
data.table(
  ExpNumStat(
    betio.v.list,
    by = "A",
    gp = NULL,
    Qnt = NULL,
    Nlim = 10,
    MesofShape = 2,
    Outlier = TRUE,
    round = 3,
    dcast = FALSE,
    val = NULL
  )
)
```


```{r eval=FALSE}
# Statistics for Numerical features by Vessel Type
data.table(
  ExpNumStat(
    betio.v.list,
    by = "GA",
    gp = "vessel_type",
    Qnt = NULL,
    Nlim = 10,
    MesofShape = 2,
    Outlier = TRUE,
    round = 3,
    dcast = FALSE,
    val = NULL
  )
)[order(-TN),
  head(.SD,
       10),
  by = Vname]
```


```{r eval=FALSE}
# Statistics for Categorigal features
data.table(
  ExpCTable(
    betio.v.list,
    Target = NULL,
    margin = 1,
    clim = 50,
    nlim = 10,
    round = 2,
    bin = 3,
    per = TRUE
  )
)[order(-Frequency),
  head(.SD,
       10),
  by = Variable]
```

## Noise Reduction 

Numerous methods are outlined to reduce noise. Replicate the procedures outlined by [UNSTATS](https://unstats.un.org/wiki/display/AIS/AIS+data+at+the+UN+Global+Platform).


### "Moving Ships" filter Algorithm

From UNSTATS: 

> The distance travelled is calculated in the "Calculate the mount of motion" block by computing the minimum and maximum of latitude and longitudes for all ship positions over the selected period. The differences in latitude and longitude, the deltas, are compared against a predefined threshold values. 

```{r eval=FALSE}

```

### "Time in Port" Indicator

From UNSTATS: 

> The "Time in Port" indicator measures the total time spent by all ships within the boundaries of the port monthly over the defined period.

Frequency of calculation: Monthly

1. Calculate time difference between sorted time messages for each MMSI saved as time deltas. 
2. Generate Port Index (arbitrary because selection is only for port bounds) + Time Period (Month) + Year


```{r eval=FALSE}
# Calculate time difference 
# Sort by mmsi and dth 
betio.v.list <- betio.v.list[order(betio.v.list$dtg),
            `:=` (time_diff_seconds = dtg - shift(dtg)),
            by = mmsi][order(betio.v.list$dtg,
                             betio.v.list$mmsi)]


# If time difference is greater than 10800 seconds remove
betio.v.list[time_diff_seconds >= 10800, 
            time_diff_seconds := 0,
            by = mmsi]


# Create index
betio.v.list[,
            index := paste0("ki-beti-tip-",
                                "-",
                                month = lubridate::month(dtg), 
                                "-",
                                year = lubridate::year(dtg))]


tim.ds <- betio.v.list[,
                 .(time_in_port_seconds = sum(time_diff_seconds,
                                              na.rm = TRUE)),
                 by = .(index,
                        month = lubridate::month(dtg),
                        year = lubridate::year(dtg),
                        vessel_type,
                        flag_country,
                        vessel_class)][time_in_port_seconds != 0]


# z <- tim.ds[,
#        .(sum_time_mins = sum(time_in_port_seconds, na.rm = TRUE)/60),
#        by = .(year,
#               month)]


# melt.data.table(ki.imts.bot,
#                                id = c("year",
#                                       "month"), measure = c("exports-fob-domestic",
#                                                             "exports-fob-reexport", 
#                                                             "exports-fob-total",
#                                                             "imports-cif",
#                                                             "trade-balance"))


tim.ds <- melt.data.table(tim.ds, 
                          id = c("index",
                                "month",
                                 "year",
                                 "vessel_type",
                                 "flag_country",
                                 "vessel_class"),
                          measure = "time_in_port_seconds")




```


### "Port Traffic" Indicator

From UNSTATS: 

> The "Port Traffic" indicator  captures how many unique ships  have been observed in port based on their reported MMSI. 

Frequency of calculation: Monthly

1. Create time period index using mmsi + port + time period (month)
2. Count Unique 

```{r eval=FALSE}
# Create index
betio.v.list[,
            index := paste0("ki-beti-ptr",
                                "-",
                                month = lubridate::month(dtg), 
                                "-",
                                year = lubridate::year(dtg))]


ptr.ds <- betio.v.list[, 
                  .(unique_count_mmsi = .N), 
                  by = .(index,
                        month = lubridate::month(dtg),
                        year = lubridate::year(dtg),
                        vessel_type,
                        flag_country,
                        vessel_class)]


# z <- ptr.ds[,
#        .(sum  = sum(unique_count_mmsi, na.rm = TRUE)),
#        by = .(year,
#               month)]


ptr.ds <- melt.data.table(ptr.ds, 
                          id = c("index",
                                "month",
                                 "year",
                                 "vessel_type",
                                 "flag_country",
                                 "vessel_class"),
                          measure = "unique_count_mmsi")



tim.ds[, value := as.integer(value)]


ki_betio_ais <- rbind(tim.ds, ptr.ds)


fwrite(ki_betio_ais, "./data/processed/ki_betio_ais.csv")


```


# Read Palau

Read the files extracted from UNGP for Betio, Kiribati. 

```{r eval=FALSE}
# pl.list files
file.list <- list.files(path = "./data/external/ais_pl/", 
                        pattern='*.csv')


# Read files in bulk
pl.list <- lapply(paste0("./data/external/ais_pl/",
                           file.list),
                  fread)


# turn into one table 
pl.list <- rbindlist(pl.list)


pl.list <- pl.list[,1:28]


head(pl.list)
```

## Exploration 

1. Convert dtg and eta to as.POSIXct(x, tz = "", ...)

```{r eval=FALSE}
# Change from char to posixct 
pl.list[,
            `:=` (dtg = gsub("T",
                             " ",
                             dtg
                             )
                  )][,
                     `:=` (dtg = gsub(".000Z",
                             "",
                             dtg
                             )
                           )]


pl.list[,
            `:=` (dtg = strptime(dtg, "%Y-%m-%d %H:%M:%S")
                  )]


# check summary 
pl.list[,
            summary(dtg)]
```


```{r eval=FALSE}
# Check out dataset quality
ExpData(
  data = pl.list,
  type = 1
  )
```


```{r eval=FALSE}
# Check out data feature quality
ExpData(
  data = pl.list,
  type = 2
  )
```


```{r eval=FALSE}
# Statistics for Numerical features 
data.table(
  ExpNumStat(
    pl.list,
    by = "A",
    gp = NULL,
    Qnt = NULL,
    Nlim = 10,
    MesofShape = 2,
    Outlier = TRUE,
    round = 3,
    dcast = FALSE,
    val = NULL
  )
)
```


```{r eval=FALSE}
# Statistics for Numerical features by Vessel Type
data.table(
  ExpNumStat(
    pl.list,
    by = "GA",
    gp = "vessel_type",
    Qnt = NULL,
    Nlim = 10,
    MesofShape = 2,
    Outlier = TRUE,
    round = 3,
    dcast = FALSE,
    val = NULL
  )
)[order(-TN),
  head(.SD,
       10),
  by = Vname]
```


```{r eval=FALSE}
# Statistics for Categorigal features
data.table(
  ExpCTable(
    pl.list,
    Target = NULL,
    margin = 1,
    clim = 50,
    nlim = 10,
    round = 2,
    bin = 3,
    per = TRUE
  )
)[order(-Frequency),
  head(.SD,
       10),
  by = Variable]
```

## Noise Reduction 

Numerous methods are outlined to reduce noise. Replicate the procedures outlined by [UNSTATS](https://unstats.un.org/wiki/display/AIS/AIS+data+at+the+UN+Global+Platform).


### "Moving Ships" filter Algorithm

From UNSTATS: 

> The distance travelled is calculated in the "Calculate the mount of motion" block by computing the minimum and maximum of latitude and longitudes for all ship positions over the selected period. The differences in latitude and longitude, the deltas, are compared against a predefined threshold values. 

```{r eval=FALSE}

```

### "Time in Port" Indicator

From UNSTATS: 

> The "Time in Port" indicator measures the total time spent by all ships within the boundaries of the port monthly over the defined period.

Frequency of calculation: Monthly

1. Calculate time difference between sorted time messages for each MMSI saved as time deltas. 
2. Generate Port Index (arbitrary because selection is only for port bounds) + Time Period (Month) + Year


```{r eval=FALSE}
# Calculate time difference 
# Sort by mmsi and dth 
pl.list <- pl.list[order(pl.list$dtg),
            `:=` (time_diff_seconds = dtg - shift(dtg)),
            by = mmsi][order(pl.list$dtg,
                             pl.list$mmsi)]


# If time difference is greater than 10800 seconds remove
pl.list[time_diff_seconds >= 10800, 
            time_diff_seconds := 0,
            by = mmsi]


# Create index
pl.list[,
            index := paste0("pl-tip-",
                                "-",
                                month = lubridate::month(dtg), 
                                "-",
                                year = lubridate::year(dtg))]


tim.ds <- pl.list[,
                 .(time_in_port_seconds = sum(time_diff_seconds,
                                              na.rm = TRUE)),
                 by = .(index,
                        month = lubridate::month(dtg),
                        year = lubridate::year(dtg),
                        vessel_type,
                        flag_country,
                        vessel_class)][time_in_port_seconds != 0]


# z <- tim.ds[,
#        .(sum_time_mins = sum(time_in_port_seconds, na.rm = TRUE)/60),
#        by = .(year,
#               month)]


# melt.data.table(ki.imts.bot,
#                                id = c("year",
#                                       "month"), measure = c("exports-fob-domestic",
#                                                             "exports-fob-reexport", 
#                                                             "exports-fob-total",
#                                                             "imports-cif",
#                                                             "trade-balance"))


tim.ds <- melt.data.table(tim.ds, 
                          id = c("index",
                                "month",
                                 "year",
                                 "vessel_type",
                                 "flag_country",
                                 "vessel_class"),
                          measure = "time_in_port_seconds")




```


### "Port Traffic" Indicator

From UNSTATS: 

> The "Port Traffic" indicator  captures how many unique ships  have been observed in port based on their reported MMSI. 

Frequency of calculation: Monthly

1. Create time period index using mmsi + port + time period (month)
2. Count Unique 

```{r eval=FALSE}
# Create index
pl.list[,
            index := paste0("pl-ptr",
                                "-",
                                month = lubridate::month(dtg), 
                                "-",
                                year = lubridate::year(dtg))]


ptr.ds <- pl.list[, 
                  .(unique_count_mmsi = .N), 
                  by = .(index,
                        month = lubridate::month(dtg),
                        year = lubridate::year(dtg),
                        vessel_type,
                        flag_country,
                        vessel_class)]


# z <- ptr.ds[,
#        .(sum  = sum(unique_count_mmsi, na.rm = TRUE)),
#        by = .(year,
#               month)]


ptr.ds <- melt.data.table(ptr.ds, 
                          id = c("index",
                                "month",
                                 "year",
                                 "vessel_type",
                                 "flag_country",
                                 "vessel_class"),
                          measure = "unique_count_mmsi")



tim.ds[, value := as.integer(value)]


pl_ais <- rbind(tim.ds, ptr.ds)


fwrite(pl_ais, "./data/processed/pl_ais.csv")


```



# Common AIS Data Schema 


Read in all aggregated AIS data. 

```{r eval=FALSE}
# list files
file.list <- list.files(path = "./data/processed/", 
                        pattern='*.csv')


# Read files in bulk
ais.data <- lapply(paste0("./data/processed/",
                           file.list),
                  fread)


# turn into one table 
ais.data <- rbindlist(ais.data)


# Create country field 
ais.data[, 
         country := substr(index, 1, 2)]



head(ais.data)
```


Get stg_trade_agg as example. 

```{r}
# Connect to a specific postgres database
db.con <- dbConnect(RPostgres::Postgres(),
                    dbname = 'aishackathon', 
                    host = 'ais-hack.cirquhp75zcc.us-east-2.rds.amazonaws.com', 
                    port = 5432, 
                    user = Sys.getenv("userid"),
                    password = Sys.getenv("pwd"))


stg_trade_agg <- data.table(RPostgres::dbGetQuery(db.con, "SELECT * FROM stg_trade_agg"))


# Preview
tail(stg_trade_agg)
```


Align Data to similar schema as stg_trade_agg. 

```{r}
# Align country labels, rename sl to sb for solomon islands 
ais.data[country == "sl", 
         country := "sb"]


# pl to pw for palau 
ais.data[country == "pl", 
         country := "pw"]


# Create region field 
ais.data[country %in% c("fj", "vn", "sb"), 
         region := "melanesia"]


ais.data[country %in% c('ck','ki'), 
         region := "polynesia"]


ais.data[country %in% c('pw','pl'), 
         region := "micronesia"]

```

Aggregate data, the reliance here is on the quality of the vessel type data feature. There are bad records and empty records (refer to the statistics below). No alternate sources to impute so these we'll be ignored in the initial study, with a look to further improve data quality in subsequent studies for the use of AIS data. 

Aggregating by vessel_type, 80.75% of the available data set will be used (ignoring bad data)

```{r}

# Check out dataset quality
ExpData(
  data = ais.data,
  type = 1
  )
```



```{r}
# expo <- data.table(
#   ExpCTable(
#     country_metrics,
#     Target = NULL,
#     margin = 1,
#     clim = 50,
#     nlim = 10,
#     round = 2,
#     bin = 3,
#     per = TRUE
#   )
# )[order(-Frequency),
#   head(.SD,
#        300),
#   by = Variable]
# 
# fwrite(expo, "./data/processed/ds_quality_stats/country_metrics_stats.csv")


# Check out data feature quality
ExpData(
  data = ais.data,
  type = 2
  )

```


```{r}
# Statistics for Categorigal features
data.table(
  ExpCTable(
    ais.data,
    Target = NULL,
    margin = 1,
    clim = 50,
    nlim = 10,
    round = 2,
    bin = 3,
    per = TRUE
  )
)[order(-Frequency),
  head(.SD,
       10),
  by = Variable]

```

Cargo Time in Port and Unique Count aggregation. 

```{r}
# Create date field 
ais.data[, 
         date := as.Date(paste0(year,"-",month,"-01"))]


# Cargo indicators
cargo.ais.tim <- ais.data[tolower(vessel_type) == "cargo" & variable == "time_in_port_seconds",
                      .(cargo_time_in_port_seconds = sum(value , na.rm = TRUE)), 
                      by = .(date,
                             region, 
                             country)]


# Cargo indicators
cargo.ais.ptr <- ais.data[tolower(vessel_type) == "cargo" & variable == "unique_count_mmsi",
                      .(cargo_uniq_mmsi_count = sum(value , na.rm = TRUE)), 
                      by = .(date,
                             region, 
                             country)]


# Remove bad data introduced by source
cargo.ais.ptr <- cargo.ais.ptr[!is.na(date)]



cargo.ais <- merge.data.table(cargo.ais.ptr, 
                              cargo.ais.tim, 
                              by = c("date", "region", "country"),
                              all = TRUE)


rm(cargo.ais.ptr, cargo.ais.tim)
```

Fishing Time in Port and Unique Count aggregation. 

```{r}
# Cargo indicators
fish.ais.tim <- ais.data[tolower(vessel_type) == "fishing" & variable == "time_in_port_seconds",
                      .(fishing_time_in_port_seconds = sum(value , na.rm = TRUE)), 
                      by = .(date,
                             region, 
                             country)]


# Cargo indicators
fish.ais.ptr <- ais.data[tolower(vessel_type) == "fishing" & variable == "unique_count_mmsi",
                      .(fishing_uniq_mmsi_count = sum(value , na.rm = TRUE)), 
                      by = .(date,
                             region, 
                             country)]


# Remove bad data introduced by source
fish.ais.ptr <- fish.ais.ptr[!is.na(date)]



fish.ais <- merge.data.table(fish.ais.ptr, 
                              fish.ais.tim, 
                              by = c("date", "region", "country"),
                              all = TRUE)


rm(fish.ais.ptr, fish.ais.tim)
```

Tanker Time in Port and Unique Count aggregation. 

```{r}
# Cargo indicators
tnkr.ais.tim <- ais.data[tolower(vessel_type) == "tanker" & variable == "time_in_port_seconds",
                      .(tanker_time_in_port_seconds = sum(value , na.rm = TRUE)), 
                      by = .(date,
                             region, 
                             country)]


# Cargo indicators
tnkr.ais.ptr <- ais.data[tolower(vessel_type) == "tanker" & variable == "unique_count_mmsi",
                      .(tanker_uniq_mmsi_count = sum(value , na.rm = TRUE)), 
                      by = .(date,
                             region, 
                             country)]


# Remove bad data introduced by source
tnkr.ais.ptr <- tnkr.ais.ptr[!is.na(date)]



tnkr.ais <- merge.data.table(tnkr.ais.ptr, 
                              tnkr.ais.tim, 
                              by = c("date", "region", "country"),
                              all = TRUE)


rm(tnkr.ais.ptr, tnkr.ais.tim)
```

Sailing and Pleasure Craft Time in Port and Unique Count aggregation. Both categories will be combined as leisure. 

```{r}
# Cargo indicators
leisure.ais.tim <- ais.data[tolower(vessel_type) %in% c("sailing", "pleasure craft") & variable == "time_in_port_seconds",
                      .(leisure_time_in_port_seconds = sum(value , na.rm = TRUE)), 
                      by = .(date,
                             region, 
                             country)]


# Cargo indicators
leisure.ais.ptr <- ais.data[tolower(vessel_type) %in% c("sailing", "pleasure craft") & variable == "unique_count_mmsi",
                      .(leisure_uniq_mmsi_count = sum(value , na.rm = TRUE)), 
                      by = .(date,
                             region, 
                             country)]


# Remove bad data introduced by source
leisure.ais.ptr <- leisure.ais.ptr[!is.na(date)]



leisure.ais <- merge.data.table(leisure.ais.ptr, 
                              leisure.ais.tim, 
                              by = c("date", "region", "country"),
                              all = TRUE)


rm(leisure.ais.ptr, leisure.ais.tim)
```

Join all into one dataset. 

```{r}
# Join
stg.ais.agg <- merge.data.table(cargo.ais, 
                                tnkr.ais, 
                                by = c("date", "region", "country"),
                                all = TRUE)


stg.ais.agg <- merge.data.table(stg.ais.agg, 
                                fish.ais, 
                                by = c("date", "region", "country"),
                                all = TRUE)


stg.ais.agg <- merge.data.table(stg.ais.agg, 
                                leisure.ais, 
                                by = c("date", "region", "country"),
                                all = TRUE)

```

Write to db. 

```{r}
# Connect to a specific postgres database
db.con <- dbConnect(RPostgres::Postgres(),
                    dbname = 'aishackathon', 
                    host = 'ais-hack.cirquhp75zcc.us-east-2.rds.amazonaws.com', 
                    port = 5432, 
                    user = Sys.getenv("userid"),
                    password = Sys.getenv("pwd"))


# # Append stg.ais.agg to stg_ais_agg
# RPostgres::dbWriteTable(db.con,
#                         "stg_ais_agg",
#                         stg.ais.agg,
#                         overwrite = TRUE,
#                         row.names = FALSE)


# Count rows after upload
chk.load <- RPostgres::dbGetQuery(db.con, "SELECT * FROM stg_ais_agg")



dbDisconnect(db.con)

```

# Tourism Data Schema 

Aggregate into the common schema.

```{r}
# Connect to a specific postgres database
db.con <- dbConnect(RPostgres::Postgres(),
                    dbname = 'aishackathon', 
                    host = 'ais-hack.cirquhp75zcc.us-east-2.rds.amazonaws.com', 
                    port = 5432, 
                    user = Sys.getenv("userid"),
                    password = Sys.getenv("pwd"))


# Count rows before upload
country_metrics <- data.table(RPostgres::dbGetQuery(db.con, "SELECT * FROM country_metrics"))


tourism.data <- country_metrics[tolower(category) == "tourism" & frequency == "monthly"]


# Align country labels, rename ki and kir
tourism.data[country == "kir", 
         country := "ki"]


# pl to pw for palau 
tourism.data[country %in% c("pl", "PW"), 
         country := "pw"]


# Create region field 
tourism.data[country %in% c("fj", "vn", "sb"), 
         region := "melanesia"]


tourism.data[country %in% c('ck','ki'), 
         region := "polynesia"]


tourism.data[country %in% c('pw','pl'), 
         region := "micronesia"]

```

Align variable names across countries before aggregating. 

```{r}
# align total-visitors for palau and vanuatu to arrivals-visitor 
tourism.data[name == "total-visitors", 
             name := "arrivals-visitor"]


# tourism indicators
tourism.data <- tourism.data[tolower(name) == "arrivals-visitor",
                      .(visitor_arrivals = value), 
                      by = .(date,
                             region, 
                             country)]


```

Write to db. 

```{r}
# Connect to a specific postgres database
db.con <- dbConnect(RPostgres::Postgres(),
                    dbname = 'aishackathon', 
                    host = 'ais-hack.cirquhp75zcc.us-east-2.rds.amazonaws.com', 
                    port = 5432, 
                    user = Sys.getenv("userid"),
                    password = Sys.getenv("pwd"))


# Append stg.ais.agg to stg_ais_agg
RPostgres::dbWriteTable(db.con,
                        "stg_tourism_agg",
                        tourism.data,
                        overwrite = TRUE,
                        row.names = FALSE)


# Count rows after upload
chk.load <- RPostgres::dbGetQuery(db.con, "SELECT * FROM stg_tourism_agg")



dbDisconnect(db.con)

```


# All Required Data Combined

Merge. 

```{r}
stg_trade_agg[, 
              date := as.Date(date)]

all.together <- merge.data.table(stg_trade_agg, 
                                 stg.ais.agg,
                                 by = c("date", "region", "country"),
                                 all = TRUE)

tourism.data[, 
             date := as.Date(date)]


all.together <- merge.data.table(all.together,
                                 tourism.data, 
                                 by = c("date", "region", "country"),
                                 all = TRUE)


# Center to mean
all.together[,
             s_trade_volume := trade_volume/mean(trade_volume, na.rm = TRUE), 
             by = country]


all.together[,
             s_cargo_uniq_mmsi_count := cargo_uniq_mmsi_count/mean(cargo_uniq_mmsi_count, na.rm = TRUE), 
             by = country]


all.together[,
             s_cargo_time_in_port_seconds := cargo_time_in_port_seconds/mean(cargo_time_in_port_seconds, na.rm = TRUE), 
             by = country]


all.together[,
             s_tanker_uniq_mmsi_count := tanker_uniq_mmsi_count/mean(tanker_uniq_mmsi_count, na.rm = TRUE), 
             by = country]


all.together[,
             s_tanker_time_in_port_seconds := tanker_time_in_port_seconds/mean(tanker_time_in_port_seconds, na.rm = TRUE), 
             by = country]


all.together[,
             s_fishing_uniq_mmsi_count := fishing_uniq_mmsi_count/mean(fishing_uniq_mmsi_count, na.rm = TRUE), 
             by = country]


all.together[,
             s_fishing_time_in_port_seconds := fishing_time_in_port_seconds/mean(fishing_time_in_port_seconds, na.rm = TRUE), 
             by = country]


all.together[,
             s_leisure_uniq_mmsi_count := leisure_uniq_mmsi_count/mean(leisure_uniq_mmsi_count, na.rm = TRUE), 
             by = country]


all.together[,
             s_leisure_time_in_port_seconds := leisure_time_in_port_seconds/mean(leisure_time_in_port_seconds, na.rm = TRUE), 
             by = country]


all.together[,
             s_visitor_arrivals := as.numeric(visitor_arrivals)/mean(as.numeric(visitor_arrivals), na.rm = TRUE), 
             by = country]

# export
fwrite(all.together,"./data/processed/pacifimpact-project-data.csv")
```


Time Series Forecasting 

Load Libraries

```{r}
# Load fable library
if (!require(fable)) {
  install.packages("fable")
  library(fable)
}

# Load DBI library
if (!require(tsibble)) {
  install.packages("tsibble")
  library(tsibble)
}

# Load tsibbledata library
if (!require(tsibbledata)) {
  install.packages("tsibbledata")
  library(tsibbledata)
}

# Load tsibbledata library
if (!require(tsibbledata)) {
  install.packages("tsibbledata")
  library(tsibbledata)
}

# Load lubridate library
if (!require(lubridate)) {
  install.packages("lubridate")
  library(lubridate)
}
```


